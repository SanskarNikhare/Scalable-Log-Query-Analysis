{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Without Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file: Index(['Level', 'Date and Time', 'Source', 'Event ID', 'Task Category',\n",
      "       'Message'],\n",
      "      dtype='object')\n",
      "Processed CSV file saved to: E:\\Sanskar\\Fourth Year\\Final Project\\FyI Project\\Preprocessing\\Log_Extraction\\Preprocessed Log Files\\modified_log_file.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Define the path for input and output files\n",
    "input_file = r'E:\\Sanskar\\Fourth Year\\Final Project\\FyI Project\\Preprocessing\\Log_Extraction\\Extracted_Log_Files\\SystemLog_2025-02-14_00-36-47.csv'  # Replace with the path to your log file\n",
    "output_folder = r'E:\\Sanskar\\Fourth Year\\Final Project\\FyI Project\\Preprocessing\\Log_Extraction\\Preprocessed Log Files'  # Replace with the path to your desired output folder\n",
    "output_file = os.path.join(output_folder, 'modified_log_file.csv')\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read the CSV log file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Clean column names by stripping leading/trailing spaces\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Print column names to check if 'Level' exists\n",
    "print(\"Columns in the CSV file:\", df.columns)\n",
    "\n",
    "# Drop the 'Task Category' column if it exists\n",
    "if 'Task Category' in df.columns:\n",
    "    df.drop(columns=['Task Category'], inplace=True)\n",
    "\n",
    "# Check if 'Level' exists before applying the filter\n",
    "if 'Level' in df.columns:\n",
    "    df = df[~df['Level'].isin(['Information', 'Warning'])]\n",
    "else:\n",
    "    print(\"'Level' column not found in the CSV file.\")\n",
    "\n",
    "# Define keywords and create a regex pattern\n",
    "keywords = [\n",
    "    'success', 'successful', 'status success', 'operation successful',\n",
    "    'operation success', 'completed successfully', 'successfully completed',\n",
    "    'task success', 'process success', 'execution success', \n",
    "    'execution successful', 'transaction success'\n",
    "]\n",
    "pattern = '|'.join(keywords)\n",
    "\n",
    "# Remove rows where 'Level' is \"Information\" and 'Message' contains keywords\n",
    "if 'Level' in df.columns:  # Only do this if 'Level' exists\n",
    "    df = df[~((df['Level'] == 'Information') & \n",
    "              df['Message'].str.contains(pattern, case=False, na=False))]\n",
    "\n",
    "# Replace special characters in 'Message'\n",
    "df['Message'] = df['Message'].apply(\n",
    "    lambda x: re.sub(r'[^\\x00-\\x7F]+', ' ', str(x))  # Remove non-ASCII characters\n",
    ")\n",
    "df['Message'] = df['Message'].apply(\n",
    "    lambda x: re.sub(r'[:;\\'-_\"<>./?\\\\|]', ' ', str(x))  # Remove special characters\n",
    ")\n",
    "\n",
    "# Normalize whitespace\n",
    "df['Message'] = df['Message'].apply(\n",
    "    lambda x: re.sub(r'\\s+', ' ', str(x)).strip()  # Replace multiple spaces with single space\n",
    ")\n",
    "\n",
    "# Remove duplicate messages while keeping the first occurrence\n",
    "df.drop_duplicates(subset=['Message'], keep='first', inplace=True)\n",
    "\n",
    "# Add a 'Threshold' column based on the 'Level' values\n",
    "if 'Level' in df.columns:\n",
    "    df['Threshold'] = df['Level'].apply(\n",
    "        lambda x: 0.8 if x == 'Error' else (0.6 if x == 'Critical' else None)\n",
    "    )\n",
    "\n",
    "# Save the processed dataframe to the output CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Print the path of the saved output file\n",
    "print(f\"Processed CSV file saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed CSV file saved to: E:\\Sanskar\\Fourth Year\\Final Project\\FyI Project\\Preprocessing\\Log_Extraction\\Preprocessed Log Files\\Modified_2025-02-14_01-10-48.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the folders for input and output files\n",
    "log_folder = r'E:\\Sanskar\\Fourth Year\\Final Project\\FyI Project\\Preprocessing\\Log_Extraction\\Extracted_Log_Files'  # Log extraction folder\n",
    "output_folder = r'E:\\Sanskar\\Fourth Year\\Final Project\\FyI Project\\Preprocessing\\Log_Extraction\\Preprocessed Log Files'  # Output folder\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "while True:\n",
    "    # Get the most recent log file generated by the first script\n",
    "    files = [f for f in os.listdir(log_folder) if f.startswith(\"SystemLog\")]\n",
    "    if not files:\n",
    "        print(\"No log files found.\")\n",
    "        break\n",
    "\n",
    "    # Sort files by modification time and pick the most recent one\n",
    "    latest_file = max(files, key=lambda f: os.path.getmtime(os.path.join(log_folder, f)))\n",
    "    input_file = os.path.join(log_folder, latest_file)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    output_file = os.path.join(output_folder, f\"Modified_{timestamp}.csv\")\n",
    "\n",
    "    # Read the CSV log file\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Clean column names by stripping leading/trailing spaces\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Drop the 'Task Category' column if it exists\n",
    "    if 'Task Category' in df.columns:\n",
    "        df.drop(columns=['Task Category'], inplace=True)\n",
    "\n",
    "    # Check if 'Level' exists before applying the filter\n",
    "    if 'Level' in df.columns:\n",
    "        df = df[~df['Level'].isin(['Information', 'Warning'])]\n",
    "    else:\n",
    "        print(\"'Level' column not found in the CSV file.\")\n",
    "\n",
    "    # Define keywords and create a regex pattern\n",
    "    keywords = [\n",
    "        'success', 'successful', 'status success', 'operation successful',\n",
    "        'operation success', 'completed successfully', 'successfully completed',\n",
    "        'task success', 'process success', 'execution success', \n",
    "        'execution successful', 'transaction success'\n",
    "    ]\n",
    "    pattern = '|'.join(keywords)\n",
    "\n",
    "    # Remove rows where 'Level' is \"Information\" and 'Message' contains keywords\n",
    "    if 'Level' in df.columns:  # Only do this if 'Level' exists\n",
    "        df = df[~((df['Level'] == 'Information') & \n",
    "                  df['Message'].str.contains(pattern, case=False, na=False))]\n",
    "\n",
    "    # Replace special characters in 'Message'\n",
    "    df['Message'] = df['Message'].apply(\n",
    "        lambda x: re.sub(r'[^\\x00-\\x7F]+', ' ', str(x))  # Remove non-ASCII characters\n",
    "    )\n",
    "    df['Message'] = df['Message'].apply(\n",
    "        lambda x: re.sub(r'[:;\\'-_\"<>./?\\\\|]', ' ', str(x))  # Remove special characters\n",
    "    )\n",
    "\n",
    "    # Normalize whitespace\n",
    "    df['Message'] = df['Message'].apply(\n",
    "        lambda x: re.sub(r'\\s+', ' ', str(x)).strip()  # Replace multiple spaces with single space\n",
    "    )\n",
    "\n",
    "    # Remove duplicate messages while keeping the first occurrence\n",
    "    df.drop_duplicates(subset=['Message'], keep='first', inplace=True)\n",
    "\n",
    "    # Add a 'Threshold' column based on the 'Level' values\n",
    "    if 'Level' in df.columns:\n",
    "        df['Threshold'] = df['Level'].apply(\n",
    "            lambda x: 0.8 if x == 'Error' else (0.6 if x == 'Critical' else None)\n",
    "        )\n",
    "\n",
    "    # Save the processed dataframe to the output CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Print the path of the saved output file\n",
    "    print(f\"Processed CSV file saved to: {output_file}\")\n",
    "\n",
    "    # Wait for 10 minutes before processing the next file\n",
    "    time.sleep(600)  # 600 seconds = 10 minutes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
